{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Semi-synthetic data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B0rRFkTKaB_p"
      },
      "source": [
        "This notebook contains the implementation for training and evaluation on the semi-synthetic dataset. This code runs on a small subset of the actual dataset used in the paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WtWMkalT2BP"
      },
      "source": [
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from contextlib import contextmanager\n",
        "import os\n",
        "import attr\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import string\n",
        "import random\n",
        "import pickle\n",
        "import numpy as np\n",
        "import itertools\n",
        "import functools\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, losses, optimizers, regularizers, metrics\n",
        "import math\n",
        "import pickle\n",
        "import scipy\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, average_precision_score, roc_auc_score, roc_curve\n",
        "import random"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dtz3KhUBT9iS"
      },
      "source": [
        "DATA_DIR = \"data/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M9h0fpebUC0U"
      },
      "source": [
        "training_data, val_data, test_data = pickle.load(open(os.path.join(DATA_DIR, \"semi_synthetic_data.pkl\"),\n",
        "                                                      \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pj04HIHrUZN0"
      },
      "source": [
        "class PaperMetadata:\n",
        "    \n",
        "    def __init__(self, paper_id, tokens, fos):\n",
        "        self.paper_id = paper_id\n",
        "        self.tokens = tokens\n",
        "        self.fos = fos\n",
        "    \n",
        "    def __str__(self):\n",
        "      return \"id=%d, fos=%s, tokens_5=%s\" % (self.paper_id, \",\".join(self.fos), \",\".join(list(self.tokens)[:5]))\n",
        "\n",
        "class PaperIdAndIndexMap:\n",
        "    \n",
        "    def __init__(self, topo_sorted_nodes):\n",
        "        self.paper_id_to_idx = {}\n",
        "        self.idx_to_paper_id = {}\n",
        "        for idx, paper_id in enumerate(topo_sorted_nodes):\n",
        "            self.paper_id_to_idx[paper_id] = idx\n",
        "            self.idx_to_paper_id[idx] = paper_id\n",
        "\n",
        "scibert_predictor_weights, paper_set, idx_to_paper_id, records = (\n",
        "    pickle.load(open(os.path.join(DATA_DIR, \"semi_synthetic_data_metadata.pkl\"), \"rb\"))\n",
        ")\n",
        "nodes_to_scibert = pickle.load(open(os.path.join(DATA_DIR, \"nodes_to_scibert_embedding_1.pkl\"), \"rb\"))\n",
        "nodes_to_scibert.update(pickle.load(open(os.path.join(DATA_DIR, \"nodes_to_scibert_embedding_2.pkl\"), \"rb\")))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B0mO6-wUk_m",
        "outputId": "dd70db52-549f-4ee2-8271-d213ef54da48"
      },
      "source": [
        "# Show an example record that represents a node in the citation graph.\n",
        "node_id = 1640247718\n",
        "print(records[node_id])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "id=1640247718, fos=engineering, tokens_5=reality,legged,problem,author,evolution\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKZd-gWdUIrd",
        "outputId": "455a7fde-f72d-4c89-9efd-c1f041e95684"
      },
      "source": [
        "# The preprocessed scibert embedding generated from the tokens using\n",
        "# bert-as-a-service [1].\n",
        "#\n",
        "# [1] https://github.com/hanxiao/bert-as-service\n",
        "nodes_to_scibert[node_id].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmF7l7u8V5nv"
      },
      "source": [
        "root_fos_map = {\n",
        "    'art': 1,\n",
        "    'biology': 2,\n",
        "    'business': 3,\n",
        "    'chemistry': 4,\n",
        "    'computer science': 5,\n",
        "    'economics': 6,\n",
        "    'engineering': 7,\n",
        "    'environmental science': 8,\n",
        "    'geography': 9,\n",
        "    'geology': 10,\n",
        "    'history': 11,\n",
        "    'materials science': 12,\n",
        "    'mathematics': 13,\n",
        "    'medicine': 14,\n",
        "    'philosophy': 15,\n",
        "    'physics': 16,\n",
        "    'political science': 17,\n",
        "    'psychology': 18,\n",
        "    'sociology': 19\n",
        "}\n",
        "root_fos_list = sorted(root_fos_map.keys())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCZT4fajU2et"
      },
      "source": [
        "# Generate the ground-truth propensity scores.\n",
        "\n",
        "NP_RANDOM_SEED = 234981293\n",
        "np.random.seed(NP_RANDOM_SEED)\n",
        "vector_size = (len(root_fos_list) + 2)**2\n",
        "is_low_propensity = np.random.binomial(1, 0.8, size=vector_size)\n",
        "propensity_vector = (\n",
        "    is_low_propensity * np.random.uniform(.1, .3, size=vector_size) + \n",
        "    (1 - is_low_propensity) * np.random.uniform(.7, 1, size=vector_size)\n",
        ")\n",
        "for i in range(1, len(root_fos_list) + 1):\n",
        "    propensity_vector[i * len(root_fos_list) + i] = np.random.uniform(0.7, 0.9)\n",
        "np.random.seed(None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wioIbkUuV9De",
        "outputId": "846f05de-09fb-49ab-88f2-88c4bd5f2437"
      },
      "source": [
        "train_citers = [i for item in training_data for i in item[\"paper_citer\"]]\n",
        "train_citeds = [i for item in training_data for i in item[\"paper_cited\"]]\n",
        "\n",
        "val_citers = [i for item in val_data for i in item[\"paper_citer\"]]\n",
        "val_citeds = [i for item in val_data for i in item[\"paper_cited\"]]\n",
        "\n",
        "test_citers = [i for item in test_data for i in item[\"paper_citer\"]]\n",
        "test_citeds = [i for item in test_data for i in item[\"paper_cited\"]]\n",
        "\n",
        "print(len(train_citeds))\n",
        "print(len(val_citeds))\n",
        "print(len(test_citeds))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "32000\n",
            "3200\n",
            "6400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pfu52O9WB1K"
      },
      "source": [
        "def add_scibert_embeddings(elements):\n",
        "    \n",
        "    def add_scibert_internal(citer_ids, cited_ids):\n",
        "        node_set = set(citer_ids.numpy()) | set(cited_ids.numpy())\n",
        "        scibert_citer = [nodes_to_scibert[idx_to_paper_id[n]] for n in citer_ids.numpy()]\n",
        "        scibert_cited = [nodes_to_scibert[idx_to_paper_id[n]] for n in cited_ids.numpy()]\n",
        "        return np.array(scibert_citer), np.array(scibert_cited)\n",
        "  \n",
        "    scibert_citer, scibert_cited = tf.py_function(add_scibert_internal,\n",
        "                                                inp=[elements[\"paper_citer\"], elements[\"paper_cited\"]],\n",
        "                                                Tout=(tf.float32, tf.float32))\n",
        "  \n",
        "    elements[\"scibert_citer\"] = scibert_citer\n",
        "    elements[\"scibert_cited\"] = scibert_cited\n",
        "    return elements\n",
        "\n",
        "def add_fos(elements):\n",
        "    \n",
        "    def add_fos_internal(paper_citer, paper_cited):\n",
        "        paper_citer = paper_citer.numpy()\n",
        "        paper_cited = paper_cited.numpy()\n",
        "\n",
        "        fos_citer = []\n",
        "        for p in paper_citer:\n",
        "            random.seed(p)\n",
        "            fos_citer.append([root_fos_map[random.choice(root_fos_list)]])\n",
        "\n",
        "        fos_cited = []\n",
        "        for p in paper_cited:\n",
        "            random.seed(p)\n",
        "            fos_cited.append([root_fos_map[random.choice(root_fos_list)]])\n",
        "\n",
        "        random.seed(None)\n",
        "        return np.array(fos_citer, np.int32), np.array(fos_cited, np.int32)\n",
        "  \n",
        "    fos_citer, fos_cited = tf.py_function(add_fos_internal,\n",
        "                                        inp=[elements[\"paper_citer\"], elements[\"paper_cited\"]],\n",
        "                                        Tout=(tf.int32, tf.int32))\n",
        "\n",
        "    elements[\"fos_citer\"] = fos_citer\n",
        "    elements[\"fos_cited\"] = fos_cited\n",
        "    return elements\n",
        "\n",
        "def add_propensity_scores(elements):\n",
        "    \n",
        "    def get_propensities_internal(fos_citer, fos_cited):\n",
        "        np.random.seed(NP_RANDOM_SEED)\n",
        "\n",
        "        fos_citer = fos_citer.numpy()\n",
        "        fos_cited = fos_cited.numpy()\n",
        "\n",
        "        propensities = []\n",
        "        for f1, f2 in zip(fos_citer, fos_cited):\n",
        "            propensities.append(propensity_vector[f1[0] * len(root_fos_list) + f2[0]])\n",
        "\n",
        "        propensities = np.array(propensities)\n",
        "        exposure = np.random.binomial(1, propensities)\n",
        "\n",
        "        np.random.seed(None)\n",
        "        return propensities, exposure\n",
        "      \n",
        "    propensities, exposure = tf.py_function(get_propensities_internal,\n",
        "                                          inp=[elements[\"fos_citer\"], elements[\"fos_cited\"]],\n",
        "                                          Tout=(tf.float32, tf.float32))\n",
        "\n",
        "    propensities.set_shape(elements[\"paper_citer\"].get_shape())\n",
        "    exposure.set_shape(elements[\"paper_citer\"].get_shape())\n",
        "\n",
        "    elements[\"propensity\"] = propensities\n",
        "    elements[\"exposure\"] = exposure\n",
        "    return elements\n",
        "\n",
        "def add_is_citation_gt(elements):\n",
        "    \n",
        "    def get_is_citation_internal(scibert_citer, scibert_cited):\n",
        "        np.random.seed(NP_RANDOM_SEED)\n",
        "\n",
        "        scibert_citer = scibert_citer.numpy()\n",
        "        scibert_cited = scibert_cited.numpy()\n",
        "\n",
        "        # shape: (batch, 768)\n",
        "        elem_prod = scibert_citer * scibert_cited\n",
        "\n",
        "        weights = scibert_predictor_weights[0]\n",
        "        bias = scibert_predictor_weights[1]\n",
        "\n",
        "        output = np.squeeze(elem_prod @ weights + bias, axis=-1)\n",
        "        citation_probs = scipy.special.expit(output)\n",
        "        is_citation = np.random.binomial(1, citation_probs)\n",
        "\n",
        "        np.random.seed(None)\n",
        "        return citation_probs, is_citation\n",
        "  \n",
        "    citation_probs, is_citation_gt = tf.py_function(get_is_citation_internal,\n",
        "                                                inp=[elements[\"scibert_citer\"], elements[\"scibert_cited\"]],\n",
        "                                                Tout=(tf.float32, tf.float32))\n",
        "\n",
        "    citation_probs.set_shape(elements[\"paper_citer\"].get_shape())\n",
        "    is_citation_gt.set_shape(elements[\"paper_citer\"].get_shape())\n",
        "\n",
        "    elements[\"citation_probs\"] = citation_probs\n",
        "    elements[\"is_citation_gt\"] = is_citation_gt\n",
        "    return elements\n",
        "\n",
        "def add_citation_using_exposure(elements):\n",
        "    elements[\"is_citation\"] = elements[\"is_citation_gt\"] * elements[\"exposure\"]\n",
        "    return elements"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9WVpq2nWD6l"
      },
      "source": [
        "def get_dataset(citers, citeds, batch_size=32, is_train=False,\n",
        "                num_batches=None):\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices({\"paper_citer\": citers,\n",
        "                                                \"paper_cited\": citeds})\n",
        "    if is_train:\n",
        "        dataset = dataset.shuffle(buffer_size=len(citers))\n",
        "\n",
        "    dataset = dataset.batch(batch_size=batch_size, drop_remainder=False)\n",
        "    if num_batches is not None:\n",
        "        dataset = dataset.take(num_batches)\n",
        "    dataset = dataset.map(add_scibert_embeddings)\n",
        "    dataset = dataset.map(add_fos)\n",
        "    dataset = dataset.map(add_propensity_scores)\n",
        "    dataset = dataset.map(add_is_citation_gt)\n",
        "    dataset = dataset.map(add_citation_using_exposure)\n",
        "    dataset = dataset.map(lambda e: (e, (e[\"is_citation\"], e[\"is_citation_gt\"])))\n",
        "    if is_train:\n",
        "        dataset = dataset.repeat()\n",
        "\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v5qZjS00WFGp",
        "outputId": "a7bb2cfa-8725-4bcc-d76b-8e338843bef6"
      },
      "source": [
        "# Test the dataset generation.\n",
        "\n",
        "for item in get_dataset(train_citers, train_citeds, batch_size=32,\n",
        "                        num_batches=1, is_train=False):\n",
        "    print(item[0].keys())\n",
        "    print(item[0][\"paper_citer\"].numpy().shape)\n",
        "    print(item[0][\"scibert_citer\"].numpy().shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['paper_citer', 'paper_cited', 'scibert_citer', 'scibert_cited', 'fos_citer', 'fos_cited', 'propensity', 'exposure', 'citation_probs', 'is_citation_gt', 'is_citation'])\n",
            "(32,)\n",
            "(32, 768)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KEJY8ToWJJ-"
      },
      "source": [
        "def fos_to_propensity_prob(fos_citer, fos_cited, embedding_fn):\n",
        "    num_fos_plus_one = 20\n",
        "\n",
        "    fos_citer = tf.cast(fos_citer, tf.float32)\n",
        "    fos_cited = tf.cast(fos_cited, tf.float32)\n",
        "\n",
        "    embeddings = embedding_fn(fos_citer * num_fos_plus_one + fos_cited)\n",
        "    return tf.sigmoid(tf.squeeze(embeddings, axis=-1))\n",
        "\n",
        "def compute_fos_idx():\n",
        "    num_fos_plus_one = 20\n",
        "    embedding_fn = layers.Embedding((num_fos_plus_one + 1)**2, 1)\n",
        "\n",
        "    fos_citer = item[0][\"fos_citer\"]\n",
        "    fos_cited = item[0][\"fos_cited\"]\n",
        "\n",
        "    print(fos_to_propensity_prob(fos_citer, fos_cited, embedding_fn))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkWzQlwtG5j9"
      },
      "source": [
        "**Loss functions using the proposed weighting schemes**\n",
        "\n",
        "The next cell contains the implementation for the loss based on the three weighting schemes proposed in the paper: $\\widehat{R}_w, \\widehat{R}_{\\text{PU}}$, and $\\widehat{R}_{\\text{AP}}$.\n",
        "\n",
        "Different weighting schemes can be used by defining a new Keras layer that computes a scalar loss based on ground-truth link probabilities, estimated link probabilities, and estimated propensities. Then this layer can be easily plugged into the training pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3SX3o7wWzp1"
      },
      "source": [
        "# Loss layers corresponding to the weighting schemes proposed in the paper. New\n",
        "# weighting schemes can be defined analogously.\n",
        "\n",
        "class RWWeightingLoss(layers.Layer):\n",
        "    \n",
        "    def __init__(self, lambda_weighting_scheme_loss, name=None):\n",
        "        super(RWWeightingLoss, self).__init__(name=name)\n",
        "        self.lambda_weighting_scheme_loss = lambda_weighting_scheme_loss\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        is_citation = inputs[0]\n",
        "        cite_prob = inputs[1]\n",
        "        propensities = inputs[2]\n",
        "        \n",
        "        propensities = tf.expand_dims(propensities, axis=-1)\n",
        "        is_citation = tf.expand_dims(is_citation, axis=-1)\n",
        "        \n",
        "        positive_weights = (1 / (propensities + 1e-5))\n",
        "        negative_weights = (1 - cite_prob) / (1 - propensities * cite_prob + 1e-5)\n",
        "        weighting = is_citation * positive_weights + (1 - is_citation) * negative_weights\n",
        "        weighting = tf.squeeze(weighting, axis=-1)\n",
        "        \n",
        "        return (\n",
        "            self.lambda_weighting_scheme_loss * tf.reduce_mean(\n",
        "                weighting * losses.binary_crossentropy(is_citation, cite_prob)))\n",
        "\n",
        "class PUWeightingLoss(layers.Layer):\n",
        "    \n",
        "    def __init__(self, lambda_weighting_scheme_loss, name=None):\n",
        "        super(PUWeightingLoss, self).__init__(name=name)\n",
        "        self.lambda_weighting_scheme_loss = lambda_weighting_scheme_loss\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        is_citation = inputs[0]\n",
        "        cite_prob = inputs[1]\n",
        "        propensities = inputs[2]\n",
        "        \n",
        "        propensities = tf.expand_dims(propensities, axis=-1)\n",
        "        is_citation = tf.expand_dims(is_citation, axis=-1)\n",
        "        \n",
        "        positive_weights = (1 / (propensities + 1e-5))\n",
        "        added_negative_weights = 1 - (1 / (propensities + 1e-5))\n",
        "        negative_weights = 1\n",
        "        weighting = is_citation * positive_weights + (1 - is_citation) * negative_weights\n",
        "        added_negative_weighting = is_citation * added_negative_weights\n",
        "        weighting = tf.squeeze(weighting, axis=-1)\n",
        "        added_negative_weighting = tf.squeeze(added_negative_weighting, axis=-1)\n",
        "        \n",
        "        return (\n",
        "            self.lambda_weighting_scheme_loss * (\n",
        "                tf.reduce_mean(weighting * losses.binary_crossentropy(is_citation, cite_prob)) +\n",
        "                tf.reduce_mean(added_negative_weighting * losses.binary_crossentropy(1 - is_citation, cite_prob))\n",
        "            )\n",
        "        )\n",
        "\n",
        "class APWeightingLoss(layers.Layer):\n",
        "    \n",
        "    def __init__(self, lambda_weighting_scheme_loss, name=None):\n",
        "        super(APWeightingLoss, self).__init__(name=name)\n",
        "        self.lambda_weighting_scheme_loss = lambda_weighting_scheme_loss\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        is_citation = inputs[0]\n",
        "        cite_prob = inputs[1]\n",
        "        propensities = inputs[2]\n",
        "        \n",
        "        propensities = tf.expand_dims(propensities, axis=-1)\n",
        "        is_citation = tf.expand_dims(is_citation, axis=-1)\n",
        "        \n",
        "        positive_weights = 1\n",
        "        negative_weights = (1 - cite_prob) / (1 - propensities * cite_prob + 1e-5)\n",
        "        added_positive_weights = cite_prob * (1 - propensities) / (1 - propensities * cite_prob + 1e-5)\n",
        "        \n",
        "        weighting = is_citation * positive_weights + (1 - is_citation) * negative_weights\n",
        "        positive_multiplier = 1\n",
        "        added_positive_weighting = (1 - is_citation) * added_positive_weights * positive_multiplier\n",
        "        weighting = tf.squeeze(weighting, axis=-1)\n",
        "        added_positive_weighting = tf.squeeze(added_positive_weighting, axis=-1)\n",
        "        \n",
        "        return (\n",
        "            self.lambda_weighting_scheme_loss * (\n",
        "                tf.reduce_mean(weighting * losses.binary_crossentropy(is_citation, cite_prob)) +\n",
        "                tf.reduce_mean(added_positive_weighting * losses.binary_crossentropy(is_citation, cite_prob))\n",
        "            )\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAC5-6x3WWPG"
      },
      "source": [
        "PAPER_TEXT_EMB_SIZE = 768\n",
        "\n",
        "@attr.s\n",
        "class TrainHParams(object):\n",
        "    # One of: (\"none\", \"MLE\" \"R_W\", \"R_PU\", \"R_AP\").\n",
        "    # This hyperparameter is used to select the weighting scheme used for\n",
        "    # training. Each setting corresponds to one of the five methods tested in\n",
        "    # our paper.\n",
        "    weighting_scheme = attr.ib(default=\"R_W\")\n",
        "    lambda_prediction = attr.ib(default=20.)\n",
        "    lambda_weighting_scheme_loss = attr.ib(default=1.)\n",
        "    lr = attr.ib(default=1e-3)\n",
        "    \n",
        "class IdentityLayer(layers.Layer):\n",
        "    \n",
        "    def __init__(self, name=None):\n",
        "        super(IdentityLayer, self).__init__(name=name)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        return inputs\n",
        "\n",
        "class EmbeddingsToPrediction(layers.Layer):\n",
        "    \n",
        "    def __init__(self, kernel_regularizer=None, name=None):\n",
        "        super(EmbeddingsToPrediction, self).__init__(name=name)\n",
        "        self.linear_classifier = layers.Dense(units=1,\n",
        "                                              activation=\"sigmoid\")\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        elem_multiply = inputs[0] * inputs[1]\n",
        "        return self.linear_classifier(elem_multiply)\n",
        "\n",
        "class FosToPropensity(layers.Layer):\n",
        "    \"\"\"This layer represents the propensity score model used in the paper.\n",
        "\n",
        "    In our work, the propensity score only depends on the fields-of-study of\n",
        "    study of the two papers.\n",
        "\n",
        "    Different propensity score models (which potentially depend on more features\n",
        "    of the node) can be incorporated in the training pipeline by redefining this\n",
        "    layer.\n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, name=None):\n",
        "        super(FosToPropensity, self).__init__(name=name)\n",
        "        self.embeddings_fn = layers.Embedding(25**2, 1)\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        fos_citer = inputs[0]\n",
        "        fos_cited = inputs[1]\n",
        "        probs = fos_to_propensity_prob(fos_citer, fos_cited, self.embeddings_fn)\n",
        "        return tf.squeeze(probs, axis=-1)\n",
        "\n",
        "class CitationLoss(layers.Layer):\n",
        "    \"\"\"Computes the binary cross-entropy loss between ground-truth citations and\n",
        "    estimated citations.\n",
        "\n",
        "    When `use_propensity` is `True`, this loss function becomes the MLE.\n",
        "    When `use_propensity` is `False`, this loss function corresponds to the\n",
        "    `No_Prop` estimator in the paper. \n",
        "    \"\"\"\n",
        "    \n",
        "    def __init__(self, use_propensity, lambda_prediction=1, name=None):\n",
        "        super(CitationLoss, self).__init__(name=name)\n",
        "        self.use_propensity = use_propensity\n",
        "        self.lambda_prediction = lambda_prediction\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        is_citation = inputs[0]\n",
        "        cite_prob = inputs[1]\n",
        "\n",
        "        if self.use_propensity:\n",
        "          propensities = inputs[2]\n",
        "          propensities = tf.expand_dims(propensities, axis=-1)\n",
        "          y_pred = cite_prob * propensities\n",
        "        else:\n",
        "          y_pred = cite_prob\n",
        "        \n",
        "        return (\n",
        "            self.lambda_prediction * tf.reduce_mean(\n",
        "                losses.binary_crossentropy(tf.expand_dims(is_citation, axis=-1), y_pred)))\n",
        "\n",
        "class CitationPredictor:\n",
        "    \n",
        "    def __init__(self, embedding_size=32, hparams=TrainHParams()):\n",
        "        self.hparams = hparams\n",
        "        self._compile_model()\n",
        "      \n",
        "    def _add_metric(self, model, metric, name):\n",
        "        model.add_metric(metric, aggregation=\"mean\", name=name)\n",
        "  \n",
        "    def _compile_model(self):\n",
        "        scibert_citer = layers.Input(shape=(PAPER_TEXT_EMB_SIZE), name=\"scibert_citer\")\n",
        "        scibert_cited = layers.Input(shape=(PAPER_TEXT_EMB_SIZE), name=\"scibert_cited\")\n",
        "        fos_citer = layers.Input(shape=(1), name=\"fos_citer\")\n",
        "        fos_cited = layers.Input(shape=(1), name=\"fos_cited\")\n",
        "        propensities = layers.Input(shape=(), name=\"propensity\")\n",
        "        is_citation = layers.Input(shape=(), name=\"is_citation\")\n",
        "        is_citation_gt = layers.Input(shape=(), name=\"is_citation_gt\")\n",
        "\n",
        "        cite_prob = EmbeddingsToPrediction(name=\"cite_prob\")([scibert_citer, scibert_cited])\n",
        "\n",
        "        cite_prob_gt = IdentityLayer(name=\"cite_prob_gt\")(cite_prob)\n",
        "\n",
        "        propensities_pred = FosToPropensity(name=\"propensities_pred\")([fos_citer, fos_cited])\n",
        "\n",
        "        self.model = keras.Model(inputs=[scibert_citer, scibert_cited, propensities, is_citation, is_citation_gt,\n",
        "                                          fos_citer, fos_cited],\n",
        "                                  outputs=[cite_prob, cite_prob_gt])\n",
        "\n",
        "        # Decide between `No_Prop` and `MLE`.\n",
        "        if self.hparams.weighting_scheme == \"none\":\n",
        "            cite_prob_loss = CitationLoss(use_propensity=False,\n",
        "                                          lambda_prediction=self.hparams.lambda_prediction)([is_citation,\n",
        "                                                                                             cite_prob])\n",
        "        else:\n",
        "            cite_prob_loss = CitationLoss(use_propensity=True,\n",
        "                                          lambda_prediction=self.hparams.lambda_prediction)([is_citation,\n",
        "                                                                                             cite_prob,\n",
        "                                                                                             propensities_pred])\n",
        "        self.model.add_loss(cite_prob_loss)\n",
        "        self._add_metric(self.model, cite_prob_loss, \"cite_prob_loss\")\n",
        "        \n",
        "        weighting_scheme_loss = None\n",
        "        # Decide which weighting scheme loss to use (if any).\n",
        "        if self.hparams.weighting_scheme == \"R_W\":\n",
        "            weighting_scheme_loss = RWWeightingLoss(\n",
        "                self.hparams.lambda_weighting_scheme_loss)([is_citation,\n",
        "                                                            cite_prob,\n",
        "                                                            propensities_pred])\n",
        "        elif self.hparams.weighting_scheme == \"R_PU\":\n",
        "            weighting_scheme_loss = PUWeightingLoss(\n",
        "                self.hparams.lambda_weighting_scheme_loss)([is_citation,\n",
        "                                                            cite_prob,\n",
        "                                                            propensities_pred])\n",
        "        elif self.hparams.weighting_scheme == \"R_PU\":\n",
        "            weighting_scheme_loss = APWeightingLoss(\n",
        "                self.hparams.lambda_weighting_scheme_loss)([is_citation,\n",
        "                                                            cite_prob,\n",
        "                                                            propensities_pred])\n",
        "\n",
        "        if weighting_scheme_loss is not None:\n",
        "          self.model.add_loss(weighting_scheme_loss)\n",
        "          self._add_metric(self.model, weighting_scheme_loss, \"weighting_scheme_loss\")\n",
        "\n",
        "        propensity_abs = tf.reduce_mean(tf.abs(propensities_pred - propensities))\n",
        "        self._add_metric(self.model, propensity_abs, \"propensity_abs\")\n",
        "\n",
        "        self.model.compile(loss=lambda yt,yp: 0.,\n",
        "                            optimizer=optimizers.Adam(learning_rate=self.hparams.lr),\n",
        "                            metrics={\"cite_prob\": [\"accuracy\",\n",
        "                                                  metrics.AUC(name=\"auc\"),\n",
        "                                                  metrics.TrueNegatives(name=\"true_negatives\"),\n",
        "                                                  metrics.FalseNegatives(name=\"false_negatives\"),\n",
        "                                                  metrics.TruePositives(name=\"true_positives\"),\n",
        "                                                  metrics.FalsePositives(name=\"false_positives\"),\n",
        "                                                  metrics.Precision(name=\"precision\"),\n",
        "                                                  metrics.Recall(name=\"recall\")],\n",
        "                                    \"cite_prob_gt\": [\"accuracy\",\n",
        "                                                  metrics.AUC(name=\"auc\"),\n",
        "                                                  metrics.TrueNegatives(name=\"true_negatives\"),\n",
        "                                                  metrics.FalseNegatives(name=\"false_negatives\"),\n",
        "                                                  metrics.TruePositives(name=\"true_positives\"),\n",
        "                                                  metrics.FalsePositives(name=\"false_positives\"),\n",
        "                                                  metrics.Precision(name=\"precision\"),\n",
        "                                                  metrics.Recall(name=\"recall\")],\n",
        "                                    }\n",
        "                          )\n",
        "\n",
        "        self.propensity_model = keras.Model(inputs=[fos_citer, fos_cited], outputs=[propensities_pred])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gasaESlTXbHd"
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "citation_predictor = CitationPredictor()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGDYtBCdXd8Q",
        "outputId": "03f25e12-9ad0-4918-e32c-9ecb83c570dd"
      },
      "source": [
        "def train_model(model):\n",
        "    batch_multiplier = 1\n",
        "    batch_size = 32 * batch_multiplier\n",
        "    num_batches = 1000\n",
        "    return model.fit(x=get_dataset(train_citers, train_citeds,\n",
        "                                 batch_size=batch_size, is_train=True,\n",
        "                                 num_batches=num_batches),\n",
        "                    validation_data=get_dataset(val_citers, val_citeds,\n",
        "                                                is_train=False,\n",
        "                                                num_batches=100),\n",
        "                    verbose=1,\n",
        "                    steps_per_epoch=num_batches,\n",
        "                    initial_epoch=0,\n",
        "                    epochs=5,\n",
        "                  )\n",
        "\n",
        "# Test training by running for a few epochs.\n",
        "train_history = train_model(citation_predictor.model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:591: UserWarning: Input dict contained keys ['paper_citer', 'paper_cited', 'exposure', 'citation_probs'] which did not match any model input. They will be ignored by the model.\n",
            "  [n for n in tensors.keys() if n not in ref_input_names])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1000/1000 [==============================] - 24s 20ms/step - loss: 5.2091 - cite_prob_loss: 4.8291 - cite_prob_gt_loss: 0.0000e+00 - cite_prob_accuracy: 0.9276 - cite_prob_auc: 0.6904 - cite_prob_true_negatives: 29653.0000 - cite_prob_false_negatives: 2245.0000 - cite_prob_true_positives: 30.0000 - cite_prob_false_positives: 72.0000 - cite_prob_precision: 0.2941 - cite_prob_recall: 0.0132 - cite_prob_gt_accuracy: 0.8438 - cite_prob_gt_auc: 0.7333 - cite_prob_gt_true_negatives: 26904.0000 - cite_prob_gt_false_negatives: 4994.0000 - cite_prob_gt_true_positives: 97.0000 - cite_prob_gt_false_positives: 5.0000 - cite_prob_gt_precision: 0.9510 - cite_prob_gt_recall: 0.0191 - weighting_scheme_loss: 0.3800 - propensity_abs: 0.3005 - val_loss: 5.1030 - val_cite_prob_loss: 4.7322 - val_cite_prob_gt_loss: 0.0000e+00 - val_cite_prob_accuracy: 0.9275 - val_cite_prob_auc: 0.7605 - val_cite_prob_true_negatives: 2964.0000 - val_cite_prob_false_negatives: 229.0000 - val_cite_prob_true_positives: 4.0000 - val_cite_prob_false_positives: 3.0000 - val_cite_prob_precision: 0.5714 - val_cite_prob_recall: 0.0172 - val_cite_prob_gt_accuracy: 0.8194 - val_cite_prob_gt_auc: 0.8457 - val_cite_prob_gt_true_negatives: 2615.0000 - val_cite_prob_gt_false_negatives: 578.0000 - val_cite_prob_gt_true_positives: 7.0000 - val_cite_prob_gt_false_positives: 0.0000e+00 - val_cite_prob_gt_precision: 1.0000 - val_cite_prob_gt_recall: 0.0120 - val_weighting_scheme_loss: 0.3707 - val_propensity_abs: 0.2974\n",
            "Epoch 2/5\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 4.7532 - cite_prob_loss: 4.4159 - cite_prob_gt_loss: 0.0000e+00 - cite_prob_accuracy: 0.9240 - cite_prob_auc: 0.7912 - cite_prob_true_negatives: 29383.0000 - cite_prob_false_negatives: 2080.0000 - cite_prob_true_positives: 186.0000 - cite_prob_false_positives: 351.0000 - cite_prob_precision: 0.3464 - cite_prob_recall: 0.0821 - cite_prob_gt_accuracy: 0.8544 - cite_prob_gt_auc: 0.8560 - cite_prob_gt_true_negatives: 26848.0000 - cite_prob_gt_false_negatives: 4615.0000 - cite_prob_gt_true_positives: 492.0000 - cite_prob_gt_false_positives: 45.0000 - cite_prob_gt_precision: 0.9162 - cite_prob_gt_recall: 0.0963 - weighting_scheme_loss: 0.3373 - propensity_abs: 0.2945 - val_loss: 4.8575 - val_cite_prob_loss: 4.5170 - val_cite_prob_gt_loss: 0.0000e+00 - val_cite_prob_accuracy: 0.9128 - val_cite_prob_auc: 0.7942 - val_cite_prob_true_negatives: 2899.0000 - val_cite_prob_false_negatives: 211.0000 - val_cite_prob_true_positives: 22.0000 - val_cite_prob_false_positives: 68.0000 - val_cite_prob_precision: 0.2444 - val_cite_prob_recall: 0.0944 - val_cite_prob_gt_accuracy: 0.8378 - val_cite_prob_gt_auc: 0.8847 - val_cite_prob_gt_true_negatives: 2603.0000 - val_cite_prob_gt_false_negatives: 507.0000 - val_cite_prob_gt_true_positives: 78.0000 - val_cite_prob_gt_false_positives: 12.0000 - val_cite_prob_gt_precision: 0.8667 - val_cite_prob_gt_recall: 0.1333 - val_weighting_scheme_loss: 0.3404 - val_propensity_abs: 0.2942\n",
            "Epoch 3/5\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 4.6220 - cite_prob_loss: 4.3018 - cite_prob_gt_loss: 0.0000e+00 - cite_prob_accuracy: 0.9160 - cite_prob_auc: 0.8174 - cite_prob_true_negatives: 28952.0000 - cite_prob_false_negatives: 1961.0000 - cite_prob_true_positives: 359.0000 - cite_prob_false_positives: 728.0000 - cite_prob_precision: 0.3303 - cite_prob_recall: 0.1547 - cite_prob_gt_accuracy: 0.8639 - cite_prob_gt_auc: 0.8836 - cite_prob_gt_true_negatives: 26707.0000 - cite_prob_gt_false_negatives: 4206.0000 - cite_prob_gt_true_positives: 938.0000 - cite_prob_gt_false_positives: 149.0000 - cite_prob_gt_precision: 0.8629 - cite_prob_gt_recall: 0.1823 - weighting_scheme_loss: 0.3203 - propensity_abs: 0.2902 - val_loss: 4.7643 - val_cite_prob_loss: 4.4362 - val_cite_prob_gt_loss: 0.0000e+00 - val_cite_prob_accuracy: 0.9006 - val_cite_prob_auc: 0.8022 - val_cite_prob_true_negatives: 2841.0000 - val_cite_prob_false_negatives: 192.0000 - val_cite_prob_true_positives: 41.0000 - val_cite_prob_false_positives: 126.0000 - val_cite_prob_precision: 0.2455 - val_cite_prob_recall: 0.1760 - val_cite_prob_gt_accuracy: 0.8531 - val_cite_prob_gt_auc: 0.8960 - val_cite_prob_gt_true_negatives: 2589.0000 - val_cite_prob_gt_false_negatives: 444.0000 - val_cite_prob_gt_true_positives: 141.0000 - val_cite_prob_gt_false_positives: 26.0000 - val_cite_prob_gt_precision: 0.8443 - val_cite_prob_gt_recall: 0.2410 - val_weighting_scheme_loss: 0.3281 - val_propensity_abs: 0.2907\n",
            "Epoch 4/5\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 4.4915 - cite_prob_loss: 4.1827 - cite_prob_gt_loss: 0.0000e+00 - cite_prob_accuracy: 0.9145 - cite_prob_auc: 0.8241 - cite_prob_true_negatives: 28814.0000 - cite_prob_false_negatives: 1831.0000 - cite_prob_true_positives: 451.0000 - cite_prob_false_positives: 904.0000 - cite_prob_precision: 0.3328 - cite_prob_recall: 0.1976 - cite_prob_gt_accuracy: 0.8710 - cite_prob_gt_auc: 0.8950 - cite_prob_gt_true_negatives: 26704.0000 - cite_prob_gt_false_negatives: 3941.0000 - cite_prob_gt_true_positives: 1167.0000 - cite_prob_gt_false_positives: 188.0000 - cite_prob_gt_precision: 0.8613 - cite_prob_gt_recall: 0.2285 - weighting_scheme_loss: 0.3088 - propensity_abs: 0.2862 - val_loss: 4.6637 - val_cite_prob_loss: 4.3459 - val_cite_prob_gt_loss: 0.0000e+00 - val_cite_prob_accuracy: 0.8975 - val_cite_prob_auc: 0.8147 - val_cite_prob_true_negatives: 2823.0000 - val_cite_prob_false_negatives: 184.0000 - val_cite_prob_true_positives: 49.0000 - val_cite_prob_false_positives: 144.0000 - val_cite_prob_precision: 0.2539 - val_cite_prob_recall: 0.2103 - val_cite_prob_gt_accuracy: 0.8606 - val_cite_prob_gt_auc: 0.9089 - val_cite_prob_gt_true_negatives: 2588.0000 - val_cite_prob_gt_false_negatives: 419.0000 - val_cite_prob_gt_true_positives: 166.0000 - val_cite_prob_gt_false_positives: 27.0000 - val_cite_prob_gt_precision: 0.8601 - val_cite_prob_gt_recall: 0.2838 - val_weighting_scheme_loss: 0.3177 - val_propensity_abs: 0.2870\n",
            "Epoch 5/5\n",
            "1000/1000 [==============================] - 19s 19ms/step - loss: 4.3579 - cite_prob_loss: 4.0615 - cite_prob_gt_loss: 0.0000e+00 - cite_prob_accuracy: 0.9130 - cite_prob_auc: 0.8362 - cite_prob_true_negatives: 28695.0000 - cite_prob_false_negatives: 1740.0000 - cite_prob_true_positives: 521.0000 - cite_prob_false_positives: 1044.0000 - cite_prob_precision: 0.3329 - cite_prob_recall: 0.2304 - cite_prob_gt_accuracy: 0.8774 - cite_prob_gt_auc: 0.9046 - cite_prob_gt_true_negatives: 26719.0000 - cite_prob_gt_false_negatives: 3716.0000 - cite_prob_gt_true_positives: 1359.0000 - cite_prob_gt_false_positives: 206.0000 - cite_prob_gt_precision: 0.8684 - cite_prob_gt_recall: 0.2678 - weighting_scheme_loss: 0.2965 - propensity_abs: 0.2823 - val_loss: 4.6348 - val_cite_prob_loss: 4.3135 - val_cite_prob_gt_loss: 0.0000e+00 - val_cite_prob_accuracy: 0.9081 - val_cite_prob_auc: 0.8185 - val_cite_prob_true_negatives: 2875.0000 - val_cite_prob_false_negatives: 202.0000 - val_cite_prob_true_positives: 31.0000 - val_cite_prob_false_positives: 92.0000 - val_cite_prob_precision: 0.2520 - val_cite_prob_recall: 0.1330 - val_cite_prob_gt_accuracy: 0.8481 - val_cite_prob_gt_auc: 0.9141 - val_cite_prob_gt_true_negatives: 2603.0000 - val_cite_prob_gt_false_negatives: 474.0000 - val_cite_prob_gt_true_positives: 111.0000 - val_cite_prob_gt_false_positives: 12.0000 - val_cite_prob_gt_precision: 0.9024 - val_cite_prob_gt_recall: 0.1897 - val_weighting_scheme_loss: 0.3214 - val_propensity_abs: 0.2837\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kR6ClsB7ezQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49182b64-af91-4b95-f19e-584681d612c4"
      },
      "source": [
        "def get_predictions(dataset, model):\n",
        "    y_true = []\n",
        "    y_pred = []\n",
        "    propensities = []\n",
        "    for item in dataset:\n",
        "        predictions = model.predict(item[0], batch_size=2048)\n",
        "        y_pred.extend(predictions[0][:, 0])\n",
        "        y_true.extend(item[0][\"is_citation\"])\n",
        "        propensities.extend(item[0][\"propensity\"])\n",
        "\n",
        "    return np.array(y_true), np.array(y_pred), np.array(propensities)\n",
        "\n",
        "y_true, y_pred, propensities = get_predictions(get_dataset(test_citers, test_citeds, \n",
        "                                                           is_train=False,\n",
        "                                                           num_batches=10),\n",
        "                                               citation_predictor.model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/functional.py:591: UserWarning: Input dict contained keys ['paper_citer', 'paper_cited', 'exposure', 'citation_probs'] which did not match any model input. They will be ignored by the model.\n",
            "  [n for n in tensors.keys() if n not in ref_input_names])\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT_KoLiqVOZW",
        "outputId": "baf86b24-f31a-4d66-c60f-41eddb29f63b"
      },
      "source": [
        "# Compute metrics on the test set.\n",
        "\n",
        "def compute_test_set_metrics(y_true, y_pred, plot_roc=False):\n",
        "    y_pred = np.array(y_pred)\n",
        "    y_pred[y_pred >= 0.5] = 1\n",
        "    y_pred[y_pred < 0.5] = 0\n",
        "    \n",
        "    print(\"precision: %f\" % precision_score(y_true,\n",
        "                          y_pred,\n",
        "                         ))\n",
        "    print(\"recall: %f\" % recall_score(y_true,\n",
        "                          y_pred,\n",
        "                         ))\n",
        "    print(\"f1 score: %f\" % f1_score(y_true,\n",
        "                          y_pred,\n",
        "                         ))\n",
        "    print(\"average precision: %f\" % average_precision_score(y_true,\n",
        "                          y_pred,\n",
        "                         ))\n",
        "    print(\"roc auc: %f\" % roc_auc_score(y_true,\n",
        "                          y_pred,\n",
        "                         ))\n",
        "    \n",
        "    if plot_roc:\n",
        "        fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
        "        plt.plot(fpr, tpr)\n",
        "        plt.xlabel(\"FPR\")\n",
        "        plt.ylabel(\"TPR\")\n",
        "\n",
        "compute_test_set_metrics(y_true, y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision: 0.375000\n",
            "recall: 0.107143\n",
            "f1 score: 0.166667\n",
            "average precision: 0.118304\n",
            "roc auc: 0.545010\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}